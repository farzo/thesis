\chapter{Vulnerability Notification Tool}
\label{vulnerability-notification-tool}
\thispagestyle{empty}

\section{Motivation}
Every day new vulnerabilities and security updates are announced. Some of these vulnerabilities affect CERN websites or web servers and could be critical. Therefore, it is important to learn about them as soon as possible and notify the owners of the affected resources to take necessary actions, i.e., patch or update their resource. The current procedure in the CERN Computer Security Team for managing vulnerabilities is as follows:
\begin{enumerate}
\item Getting informed about vulnerabilities from various sources by monitoring public databases, project mailing lists, security mailing lists, twitter accounts, blogs, etc.
\item Deciding if a vulnerability is worth investigating and is likely to affect CERN (human decision).
\item In case of vulnerabilities related to web applications, the next step is to review the output of WAD on all CERN websites and web servers, in order to get a list of resources that could be affected.
\item Sending notifications to the resource owners after making sure that the resource is in fact vulnerable, i.e., runs a vulnerable version or has a vulnerable configuration.
\end{enumerate}

The main goal of the Vulnerability Notification Tool (VNT) is to automate this procedure as much as possible and optimize each step of the process. Staying up-to-date with vulnerability sources and announcements is a time consuming task and it is hard to know if one is monitoring the best sources. With the current procedure, it is probable to overlook some vulnerabilities that are important for CERN, but do not create much noise in the public. 
On the other hand, so many vulnerabilities are published every day that makes it impossible to investigate every single one of them even if we know about all of them.

Figure \ref{figure:vulns_per_year}\footnote{Picture taken from \url{http://web.nvd.nist.gov/view/vuln/statistics-results?adv_search=true&cves=on&pub_date_start_month=0&pub_date_start_year=2000&pub_date_end_month=11&pub_date_end_year=2014}} shows the trend in the number of vulnerabilities published in the last 15 years. Apparently, 2014 with almost 8000 vulnerabilities has been the worst year for security. Due to the ever increasing volume of public vulnerability reports, the CVE MITRE vulnerability repository has even updated the CVE-ID syntax since January 2015. The new syntax, unlike the previous 4-digit one, allows identifying more than 9999 vulnerabilities each year.\footnote{\url {https://cve.mitre.org/cve/identifiers/syntaxchange.html}} 
\\
VNT tries to save the organization time by filtering out the non-critical vulnerabilities or the vulnerabilities that do not affect CERN, so that more time can be spent on remediation of the remaining ones rather than detection of the less important ones.


\begin{figure}[h!]
\label{figure:vulns_per_year}
  \centering
    \includegraphics[width=1.0\textwidth]{vulns_per_year}
  \caption{Number of Vulnerabilities Per Year}
  
\end{figure}

%\section{Related Work}
%
%\subsection{Cassandra}

\section{Source Evaluation}
\label{source_evaluation}
There are plenty of public sources that announce vulnerabilities or maintain a database of all vulnerabilities over years. The performance of VNT very much depends on the quality of the source it is using. Obviously, it is not possible to find a perfect source. For example, there is a trade-off between the speed of publishing the vulnerabilities and accuracy of the information published; hence, it is crucial to know the needs of the organization and choose the best fitting source.

\subsection{Approach}
In order the evaluate the vulnerability sources the following evaluation factors have been considered:
\begin{enumerate}
\item \textbf{Completeness}: Does the source contain all the vulnerabilities that CERN would probably care about? 
\item \textbf{Speed}: How long, since the disclosure, does it take for the vulnerability to be published?
\item \textbf{Information Quality}: What information ( e.g., severity level, exploits, solutions) about a vulnerability is published?
\item \textbf{Parsable Feed} Does the source provide a parsable feed that can be downloaded and updated automatically?
\item \textbf{Cost} Is the source free for public use? If not, how much does it cost?
\end{enumerate} 

Table \ref{table:sample_vulns} contains 6 vulnerabilities published over the last few months. These vulnerabilities have been used as case studies to evaluate completeness and speed of different sources. These vulnerabilities were of great importance for CERN and can be a good indicator of how well a source fits CERN needs.
\begin{table}
\begin{center}
    \begin{tabular}{ | c | c | c| }
    
    \hline
    \hhline{|*3-}
	\rowcolor{LightBlue}    
    \textbf{Vulnerability} & \textbf{CVE-ID} & \textbf{Disclosure Date} 
    %& Summary 
    \\ \hline
    GitLab groups API & CVE-2014-8540 & 30.10.2015
%     & The vulnerability allows a guest user to delete the owner of a group and to assign any other member as owner through the groups API.
      \\ \hline
    Wordpress 4.0.1 Security Release & CVE-2014-9032(*)  & 20.11.2014
    % & XSS vulnerability allows remote attackers to inject arbitrary web script or HTML via unspecified vectors.[...]\footnote{\url{https://wordpress.org/news/2014/11/wordpress-4-0-1/}} 
    \\ \hline
    Drupal SQL injection
 & CVE-2014-3704
 & 15.10.2014 
 %& The vulnerability allows remote attackers to conduct SQL injection attacks via an array containing crafted keys
  \\
    \hline

 Poodle
 & CVE-2014-3566
 & 14.10.2014
 %& The SSL protocol 3.0 allows man-in-the-middle attackers to obtain clear text data via a padding-oracle attack
  \\
    \hline

Twiki Remote Code Execution
 & CVE-2014-7236
 & 09.10.2014
 %& The debugenableplugins request parameter allows arbitrary Perl code execution.  
 \\
    \hline

ShellShock
 & CVE-2014-6271
 & 24.09.2014
 %& Via certain applications, a local or remote attacker may inject shell commands, allowing local privilege escalation or remote command execution depending on the application vector. 
  \\
    \hline

    \end{tabular}
    \caption{Sample vulnerabilities}
    \label{table:sample_vulns}
     \footnotesize{(*) Multiple vulnerabilities (CVE-2014-9032, CVE-2014-9033, CVE-2014-9034, CVE-2014-9035, CVE-2014-9036, CVE-2014-9037) were released at the same time.}
   \end{center}
   
\end{table}


\subsection{Vulnerability Sources}
\label{vuln_sources}
There are plenty of mailing lists, databases, vulnerability sources, etc. which are available online. Each of these sources provides different types of information for different purposes. A part of this project was to do some research on these different sources and compare them with respect to CERN needs. In this section, we will go through a summary of the sources that were evaluated. 
\begin{itemize}
\item \textbf{Natinal Vulnerability Database (NVD)}\footnote{\url{https://nvd.nist.gov/}}: The U.S. government repository of standards-based vulnerability management data
\item \textbf{Open Sourced Vulnerability Database (OSVDB)}\footnote{\url{www.osvdb.or}}: An independent and open sourced\footnote{The data is collected from publicly available sources} web-based vulnerability database created for the security community. 
\item \textbf{CVE Details}\footnote{\url{http://www.cvedetails.com/}}: A web interface providing CVE vulnerability data and statistics about vendors and products
\item \textbf{Secunia Vulnerability Intelligence Manager (VIM)}\footnote{\url{http://secunia.com/vulnerability_intelligence}}: An online service providing a filtered feed of verified vulnerability intelligence in real-time

\end{itemize}
\paragraph{Completeness and Speed}
Table \ref{table:source_speed} illustrates the publication date of sample vulnerabilities on individual sources. If a source is missing a particular vulnerability the corresponding cell is empty. Using this table we can compare the completeness and speed of different sources. Note that in each row, the fastest source is marked in green, the slowest in red and the average ones are marked in yellow. Taking a glance at the table, we can realize that OSVDB has the highest publication speed and is the most complete source.

\begin{table}
\begin{center}
    \begin{tabular}{ | c || c | c | c | c | c | c |}
    
    \hline
	
      Vulnerability(*) & \textbf{NVD}  &  \textbf{OSVDB} & \textbf{CVE Details} & \textbf{Secunia VIM} 
	\\ 
	\hline  
%	\hhline{|*5-}  
	\textbf{GitLab} & \multicolumn{1}{c|}{\cellcolor{red!25}} & \multicolumn{1}{c|}{\cellcolor{green!25} 31.10.2014} & \multicolumn{1}{c|}{\cellcolor{red!25}} & \multicolumn{1}{c|}{\cellcolor{red!25}} 
    \\ 
	\hline   
%	\hhline{~|*4-} 
	 \textbf{Wordpress} & \multicolumn{1}{c|}{\cellcolor{yellow!25} 25.10.2014} & \multicolumn{1}{c|}{\cellcolor{green!25} 21.10.2014} & \multicolumn{1}{c|}{\cellcolor{red!25}} & \multicolumn{1}{c|}{\cellcolor{green!25} 21.10.2014} 
	  \\ 
	\hline
%	\hhline{~|*4-} 
	 \textbf{Drupal} & \multicolumn{1}{c|}{\cellcolor{yellow!25}17.10.2014} & \multicolumn{1}{c|}{\cellcolor{yellow!25}17.10.2014} & \multicolumn{1}{c|}{\cellcolor{yellow!25}17.10.2014} & \multicolumn{1}{c|}{\cellcolor{green!25}16.10.2014}
	  \\ 
	\hline
%	\hhline{~|*4-} 
	 \textbf{Poodle} & \multicolumn{1}{c|}{\cellcolor{yellow!25}16.10.2014} & \multicolumn{1}{c|}{\cellcolor{yellow!25}19.10.2014} & \multicolumn{1}{c|}{\cellcolor{yellow!25}16.10.2014} & \multicolumn{1}{c|}{\cellcolor{green!25}15.10.2014}
	  \\ 
	\hline 
%	\hhline{~|*4-} 
	 \textbf{Twiki} & \multicolumn{1}{c|}{\cellcolor{red!25}} & \multicolumn{1}{c|}{\cellcolor{green!25} 09.10.2014} & \multicolumn{1}{c|}{\cellcolor{yellow!25} 11.10.2014} &\multicolumn{1}{c|}{\cellcolor{red!25}}
	  \\ 
	\hline 
%	\hhline{~|*4-} 
	 \textbf{ShellShock} & \multicolumn{1}{c|}{\cellcolor{green!25}25.09.2014} & \multicolumn{1}{c|}{\cellcolor{green!25}25.09.2014} & \multicolumn{1}{c|}{\cellcolor{green!25}25.09.2014} &\multicolumn{1}{c|}{\cellcolor{green!25} 25.09.2014} 
	 \\
	 \hline
    %\hhline{|*5-}
     
%\hhline{~~|-|~|-|}
%Critical\textsuperscript{*} & 190  & \multicolumn{1}{|c||}{\cellcolor{green!25}9}  & 622  & \multicolumn{1}{|c|}    
\end{tabular}
    \caption{Vulnerability Publication Dates}
    \label{table:source_speed}
    \footnotesize{(*) For the complete name of the vulnerability refer to Table \ref{table:sample_vulns}}
   \end{center}
    \end{table}


\paragraph{Information Quality}
The comparison of the information quality in different sources is illustrated in Table \ref{table:info_quality}. All sources have almost the same quality of the information. It is true that NVD provides less information than the other sources, but it is still providing most of the important fields that we are interested in. 



\begin{table}
\begin{center}
    \begin{tabular}{ | c || c | c | c | c | c | c |}
    
    \hline
	 
      Data & \textbf{NVD}  &  \textbf{OSVDB} & \textbf{CVE Details} & \textbf{Secunia VIM} 
	\\ 
	\hline  
%	\hhline{~|*4-}  
	\textbf{Description} & \multicolumn{1}{c|}{\cellcolor{green!25}\cmark} & \multicolumn{1}{c|}{\cellcolor{green!25}\cmark}
	& \multicolumn{1}{c|}{\cellcolor{green!25}\cmark}& \multicolumn{1}{c|}{\cellcolor{green!25}\cmark}
    \\ 
	\hline   
%	\hhline{~|*4-} 
	 \textbf{Severity} & \multicolumn{1}{c|}{\cellcolor{green!25}\cmark} & \multicolumn{1}{c|}{\cellcolor{green!25}\cmark}
	& \multicolumn{1}{c|}{\cellcolor{green!25}\cmark}& \multicolumn{1}{c|}{\cellcolor{green!25}\cmark}
	  \\ 
	\hline
%	\hhline{~|*4-} 
	 \textbf{Product} & \multicolumn{1}{c|}{\cellcolor{green!25}\cmark} & \multicolumn{1}{c|}{\cellcolor{green!25}\cmark}
	& \multicolumn{1}{c|}{\cellcolor{green!25}\cmark}& \multicolumn{1}{c|}{\cellcolor{green!25}\cmark}
	  \\ 
	\hline
%	\hhline{~|*4-} 
	 \textbf{Exploits} & \multicolumn{1}{c|}{\cellcolor{red!25}\xmark} & \multicolumn{1}{c|}{\cellcolor{red!25}\xmark}
	& \multicolumn{1}{c|}{\cellcolor{green!25}\cmark}& \multicolumn{1}{c|}{\cellcolor{red!25}\xmark}
	  \\ 
	\hline 
%	\hhline{~|*4-} 
	 \textbf{Solution} & \multicolumn{1}{c|}{\cellcolor{red!25}\xmark} & \multicolumn{1}{c|}{\cellcolor{green!25}\cmark}
	& \multicolumn{1}{c|}{\cellcolor{red!25}\xmark}& \multicolumn{1}{c|}{\cellcolor{green!25}\cmark}
	  \\ 
	\hline 
%	\hhline{~|*4-} 
	 \textbf{Vulnerability Type} & \multicolumn{1}{c|}{\cellcolor{green!25}\cmark} & \multicolumn{1}{c|}{\cellcolor{green!25}\cmark}
	& \multicolumn{1}{c|}{\cellcolor{green!25}\cmark}& \multicolumn{1}{c|}{\cellcolor{green!25}\cmark}
	 \\
	 \hline	 

    %\hhline{|*5-}
     
%\hhline{~~|-|~|-|}
%Critical\textsuperscript{*} & 190  & \multicolumn{1}{|c||}{\cellcolor{green!25}9}  & 622  & \multicolumn{1}{|c|}    
\end{tabular}
    \caption{Source Information Quality}
    \label{table:info_quality}
   \end{center}
    \end{table}
    
    
    
    
    
\paragraph{Parsable Feed and Cost}
Table \ref{table:source_evaluation} illustrates a summary of the source evaluation results. Like the two previous tables, green cells show a high evaluated score, yellow represents an average score and red is marking an unacceptable score. NVD provides free XML data feeds. OSVDB provides information via the web interface as a free resource for the community. Alternate methods of obtaining the data such as API or exports are no longer supported via OSVDB and are offered by Risk Based Security as a commercial product, called VulnDB API. CVE Details offers JSON feeds for the vulnerabilities, but unfortunately, the feeds are not complete and they do not contain vulnerable product information which is one of the most important fields for the purpose of VNT. Secunia VIM is also a commercial product\footnote{A trial account was used for evaluation} and it provides vulnerability information via a web portal. It is possible to download XML description of vulnerabilities limited to the last 72 hours; however, the main focus of VIM is on vulnerability management through the graphical web interface. 
    
    
    
    
    
    \begin{table}
\begin{center}
    \begin{tabular}{ | c || c | c | c | c | c | c |}
    
    \hline
	 
      Data & \textbf{NVD}  &  \textbf{OSVDB} & \textbf{CVE Details} & \textbf{Secunia VIM} 
	\\ 
	\hline  
%	\hhline{~|*4-}  
	\textbf{Completeness} & \multicolumn{1}{c|}{\cellcolor{yellow!25}} & \multicolumn{1}{c|}{\cellcolor{green!25}}
	& \multicolumn{1}{c|}{\cellcolor{yellow!25}}& \multicolumn{1}{c|}{\cellcolor{yellow!25}}
    \\ 
	\hline   
%	\hhline{~|*4-} 
	 \textbf{Speed} & \multicolumn{1}{c|}{\cellcolor{green!25}} & \multicolumn{1}{c|}{\cellcolor{green!25}}
	& \multicolumn{1}{c|}{\cellcolor{green!25}}& \multicolumn{1}{c|}{\cellcolor{green!25}}
	  \\ 
	\hline
%	\hhline{~|*4-} 
	 \textbf{Information Quality} & \multicolumn{1}{c|}{\cellcolor{green!25}} & \multicolumn{1}{c|}{\cellcolor{green!25}}
	& \multicolumn{1}{c|}{\cellcolor{green!25}}& \multicolumn{1}{c|}{\cellcolor{green!25}}
	  \\ 
	\hline
	 \textbf{Feed Completeness} & \multicolumn{1}{c|}{\cellcolor{green!25}} & \multicolumn{1}{c|}{\cellcolor{green!25}VulnDB}
	& \multicolumn{1}{c|}{\cellcolor{red!25}}& \multicolumn{1}{c|}{\cellcolor{red!25}}
	 \\
	 \hline
	 
	 \textbf{Feed Cost} & \multicolumn{1}{c|}{\cellcolor{green!25}} & \multicolumn{1}{c|}{\cellcolor{red!25}VulnDB}
	& \multicolumn{1}{c|}{\cellcolor{green!25}}& \multicolumn{1}{c|}{\cellcolor{white!25}*}
	 \\
	 \hline
    %\hhline{|*5-}
     
%\hhline{~~|-|~|-|}
%Critical\textsuperscript{*} & 190  & \multicolumn{1}{|c||}{\cellcolor{green!25}9}  & 622  & \multicolumn{1}{|c|}    
\end{tabular}
    \caption{Source Evaluation}
    \label{table:source_evaluation}
    \footnotesize{(*) No negotiation was done on the price, because of the incomplete feed}
   \end{center}
    \end{table}

\subsection{Conclusion}
Downloading the latest vulnerability information automatically is one of the requirements of VNT. In addition, VNT is supposed to analyze the vulnerability data to filter out the non-critical vulnerabilities and those unrelated to CERN; therefore, it is important to have the vulnerability information in a structured and parsable format. 
The only sources that provide a useful parsable feed are NVD, OSVDB and Secunia VIM. Secunia VIM focuses on vulnerability management, assuming that there is a human using its portal and taking necessary actions. There is no easy way of connecting it to another tool, i.e. WAD, and it is missing an API access. Although an XML description of vulnerabilities from last 72 hours can be downloaded in a semi-automatic way, by using tools like wget, we decided not to go for Secunia VIM, because buying the whole product and using only a non-main functionality of it was not beneficial.
\paragraph{}
Table \ref{table:source_evaluation} show clearly that OSVDB is faster, more complete and more informative than NVD. In spite of that, NVD was the source we finally used for implementation of VNT, because OSVDB is offering the API access and its feed commercially (under the name VulnDB API), but due to the disagreement while negotiating the price, we were not able to acquire the license.
\paragraph{}
Although it has not been a decision factor, it is worth mentioning that vulnerability databases use different methods of abstraction. Some, like NVD, keep one entry per vulnerability, while some others, like Secunia VIM, create multiple entries for the same vulnerability, because there are different patches available (on different operating systems, for example).

\section{National Vulnerability Database}
NVD is the U.S. government repository of standards-based vulnerability management data and contains 68054 CVE vulnerabilities. It is recommended by CVE MITRE\footnote{https://cve.mitre.org/} to obtain information about a vulnerability severity rating, fix information,vulnerable software versions, etc. 
 
\subsection{Data Feeds}
The entire NVD can be downloaded on its web page for free and for public use. The XML vulnerability feed contains security related software flaws. Each vulnerability in the file includes a description and associated reference links from the CVE dictionary feed, as well as a CVSS base score\footnote{Common Vulnerability Scoring System is a standard measurement system for rating the severity of IT vulnerabilities}, vulnerable product configuration, and weakness categorization. The feed provides vulnerability information since 1999 (one file for each year, except that the file from 2002 includes all vulnerabilities published in 2002 and before). In addition, there is a ``recent'' feed, listing recently published vulnerabilities and a ``modified" feed, which includes the ``recent" feed plus all recently modified vulnerabilities. By ``recently", we mean the previous eight days. The feeds are updated approximately every two hours.


\subsection{Challenges}
\subsubsection{Downloading}
The ``modified" feed from NVD contains the latest vulnerabilities published or modified in the last 8 days. Obviously, if the tool is not used for more than eight days, it will definitely miss some updates. This issue can be fixed by looking at the yearly feeds and detecting if a vulnerability information has changed in those feed since the last execution. Anyhow, it was decided that the tool will be used at least once a day and therefore there is no need for consulting the yearly feeds. 
Another point worth mentioning is that NVD keeps no record of the changes that happen in vulnerability data. It is impossible to see how a vulnerability has changed over time, because new data are always overwriting the old ones. VNT does not care about any intermediate changes in a vulnerability information between two subsequent executions, but for a complete evaluation of the tool and in order to be able to simulate the tool over a period of time, we kept a local copy of the ``modified" feed, downloaded daily since October 31\textsuperscript{th}, 2014. 
\subsubsection{Modification Date}
Since NVD provides the last modified date as one of the fields in the vulnerability information, the easiest way to find the vulnerabilities that have changed since the last execution of the tool, would be to compare their last modified time with the time of the last execution. However, this method will not work as the last modified time reported by NVD is not always correct. Imagine there is a vulnerability X published at time t$_{\text{0}}$. If we look at the NVD feed at time t$_{\text{2}}$ we see that the last modified time for the vulnerability is t$_{\text{0}}$, which means that the vulnerability has not changed since its publication. Now we look at the vulnerability at time t$_{\text{3}}$ and to our surprise, we may see that the last modified time is t$_{\text{1}}$  (t$_{\text{0}}$<t$_{\text{1}}$<t$_{\text{2}}$). This means that although the vulnerability information was updated at time t$_{\text{1}}$, the update was not visible for sometime and we missed it at time t$_{\text{2}}$. If we compare the last modified time (t$_{\text{1}}$) to the last execution time (t$_{\text{2}}$) we might decide to ignore the vulnerability and assume it has not changed. 
\paragraph{}
A script was written to check for existence of similar cases in NVD feeds and many instances of this controversy were found. For example, on 05.11.2014 the last modified time of CVE-2012-5500 was reported as 03.11.2014 and if we check for the same vulnerability on 06.11.2014 we get the last modified time as 04.11.2014. In addition, one can observe that sometimes the details of a vulnerability, such as its CVSS score change without changing the last modified field. Due to these problems, it decided to ignore the last modified time field completely and use the following alternative solution to find updated vulnerabilities:
\paragraph{}
The tool stores a local copy of vulnerability information (one JSON file per vulnerability). For each vulnerability in the downloaded feed we look at our local version of that vulnerability. If there is no local version, the vulnerability is reported as newly published and its data is stored locally, otherwise we compare the local version with the new data, report the changes and update the stored data.
\paragraph{}
This solution solves the modification time problem and makes it possible to report what exactly has changed in a vulnerability. 

\subsubsection{Vulnerable Configuration}
In addition to the list of vulnerable softwares, NVD provides a list of vulnerable configurations. For example, if Safari 5.0.5 is vulnerable only on Mac OS X 10.5.8 the vulnerable software list would contain Safari 5.0.5 but no information about the operating system. In this case, it would be useful to extract the configuration data from NVD and use it to make sure when a resource is vulnerable. Given the scope of this project, unavailability of configuration specifications on CERN resources and the fact that only a few vulnerabilities are bound to a specific configuration, we decided to ignore this field and only consider the products from the vulnerable-software-list field. 




\section{Product Name Matching}
\label{name_matching}
The next step after extracting new and modified vulnerabilities is to find the CERN resources that might be affected by these vulnerabilities. As an intermediate step, it is important to find which WAD names are affected by each vulnerability. If we know about the affected WAD names, finding the resources is an easy task of going over WAD output on all websites and web servers at CERN and reporting the URLs. 

\subsection{Common Platform Enumerations}
NVD is using the Common Platform Enumeration syntax to list the vulnerable softwares for each vulnerability. The Common Platform Enumeration (CPE) is a structured naming schema for IT systems, platforms and packages. It aims at providing a formal, consistent and uniform naming schema, so that the community members are able to generate names for new IT platforms in a consistent and predictable way.\footnote{\url{https://nvd.nist.gov/cpe.cfm}} This will facilitate automation in security practices. CPE is based on the generic syntax for Uniform Resource Identifiers. A standard CPE name is in the format of \texttt{cpe:/\{type\}:\{vendor\}:\{name\}:\{version\}}. The type of a platform can be either hardware (h), operating system (o), or application environment (a). Some CPEs can contain more components to provide additional information. Table \ref{table:sample_cpes} contains some examples of CPE names. 
%todo reference to cpe spec
\begin{table}
\begin{center}
    \begin{tabular}{ | c | c | }
    
    \hline
	 \hhline{|*2-}
	%\rowcolor{LightBlue}   
     \multicolumn{1}{|c|}{\cellcolor{LightBlue}\textbf{CPE}} &  \multicolumn{1}{|c|}{\cellcolor{LightBlue}\textbf{Description}}  
    \\ \hline
    % cpe:/o:microsoft:windows_xp:::home
    % cpe:/h:samsung:galaxy_note_2:-"
    % cpe:/a:wordpress:wordpress:1.0
    \multirow{3}{*}{\texttt{cpe:/h:samsung:galaxy\_note\_2:-}} & Samsung Galaxy Note 2 \\ & (Hardware) \\ & 
        \\ \hline
   \multirow{3}{*}{\texttt{cpe:/o:microsoft:windows\_xp:home}} & Microsoft Windows XP \\ & Home Edition \\ & Operating System
        \\ \hline
         \multirow{3}{*}{\texttt{cpe:/a:wordpress:wordpress:1.0}} &  \\ & Wordpress 1.0 \\ & 
        \\ \hline
    \end{tabular}
    \caption{CPE Examples}
    \label{table:sample_cpes}
   \end{center}
    
\end{table}

In this project we only care about vulnerabilities that affect operating systems or applications, therefore, we can ignore the hardware related vulnerabilities when mapping CPE to WAD names. As you can see in the examples, the first three components of the CPE (after the type indicator) are the ones that describe the vulnerable software in the format of \texttt{\{vendor\}:\{name\}:\{version\}}.
 

\subsection{WAD Product Names}
%TODO: refer to section wad
As already described in section \ref{sec:tools}, WAD uses detection rules coming from Wappalyzer which is an open source browser plugin with a community of over 100 contributors. Wappalyzer relies on its contributors' common sense to choose a meaningful name for each technology it detects and therefore there is no standard syntax for Wappalyzer names. As of the time of writing this thesis, Wappalyzer detects 707 technologies from 50 different categories.


\subsection{Approach}

There are two approaches that we can take to do the mapping from CPE names to WAD names.
\begin{enumerate}
\item \textbf{Static Mapping}: In static mapping we would need to create a dictionary that lists all WAD names for each CPE name. Generating this dictionary for the first time would be a time consuming manual work, but would guarantee a high level of accuracy. This dictionary needs to be updated whenever there is a new WAD name or CPE name. 
\item \textbf{Dynamic Mapping}: In the dynamic mapping approach we would need to design an algorithm that would find WAD names for a CPE name on the fly. By Using this approach, there would be no need for any maintenance, except optionally improving the matching algorithm. But the price we pay with dynamic mapping is lower accuracy, i.e more false positives and false negatives.  
\end{enumerate} 



\subsubsection{Challenges}
The lack of a standard naming approach in Wappalyzer and consequently in WAD, makes it difficult to match CPE names to WAD names. On the other hand, CPE itself is not 100\% consistent and sometimes for the same application one can find multiple CPE names, e.g. \texttt{cpe:/a:django\_piston\_project:django\_piston:0.2.2.0}, \texttt{cpe:/a:djangoproject:django\_piston:0.2.2.0} and \texttt{cpe:/a:djangoproject:piston:0.2.2.0} are used CPE names that refer to the same application.
\paragraph{}
There is an official CPE dictionary available online that is supposed to provide an agreed upon list of official CPE names.\footnote{\url{https://nvd.nist.gov/cpe.cfm}} Unfortunately, one can notice that many of the CPE names that appear on NVD vulnerability feeds are not present in this dictionary and therefore there is no way of knowing which CPEs we are going to find in vulnerability feeds, in advance. Considering the CPE dictionary as well as all the vulnerabilities published on NVD, currently there are 33615 number of unique CPE names (considering the vendor and product name and ignoring other components such as version). Table \ref{table:cpe_wad_mapping} tries to show how challenging it might be to find equivalent WAD names of a CPE name.

\begin{table}
\begin{center}
    \begin{tabular}{ | c | c | }
    
    \hline
	 \hhline{|*2-}
%	\rowcolor{LightBlue}   
    \multicolumn{1}{|c|}{\cellcolor{LightBlue}\textbf{CPE}} & \multicolumn{1}{|c|}{\cellcolor{LightBlue}\textbf{WAD Name}  }
    \\ \hline
    % cpe:/o:microsoft:windows_xp:::home
    % cpe:/h:samsung:galaxy_note_2:-"
    % cpe:/a:wordpress:wordpress:1.0
    \texttt{cpe:/a:adobe:coldfusion:8.0} & Adobe ColdFusion 
        \\ \hline
    \texttt{cpe:/a:yandex.metrics\_project:yandex\_metrics:1.0} & Yandex.Metrika
        \\ \hline
    \texttt{cpe:/a:woothemes:woocommerce\_plugin:2.1.0} & WooCommerce
        \\ \hline
 	\texttt{cpe:/a:djangoproject:django:1.6} & Django CMS 
        \\ \hline
    \texttt{cpe:/a:cagintranetworks:getsimple\_cms:1.0} & GetSimple CMS

        \\ \hline
    \texttt{cpe:/a:drupal:drupal:4.6.2} & Drupal
        \\ \hline
    \end{tabular}
    \caption{CPE to WAD Name Mapping}
    \label{table:cpe_wad_mapping}
   \end{center}
    
\end{table}



\subsection{Algorithm}


Considering the challenges we discussed in the previous section and the likelihood of new CPEs appearing, as well as the overload of maintaining a dictionary of the mappings, it was decided to go for a dynamic mapping approach. 
\pragraph{}
Coming up with a matching algorithm that is complete and accurate at the same time is not an easy task. The more complete the matching is (higher recall), the less accurate it is going to be (lower precision). After analyzing the list of CPE names and WAD names and trying different matching algorithms, two algorithms were designed. Algorithm \ref{matching_algo} is a an algorithm that matches a CPE name to WAD names with a high level of accuracy. A match is found only if the WAD name is the combination of CPE product and vendor names or it equals the CPE product name. Algorithm \ref{matching_algo_2} adds more matches, but has a lower level of accuracy. The user can choose to use only algorithm \ref{matching_algo} for a higher precision or both algorithms together to get a higher recall rate. Note that both algorithms receive the CPE and WAD names in lower case with leading and trailing white spaces removed. In the first algorithm these names are being normalized before they are used, which means that all punctuation marks and white spaces inside the names are removed.  
%\begin{framed}
\begin{algorithm}
\begin{algorithmic}
\STATE $matches\gets$ array()
\STATE $cpe\_name\gets$ normalize($cpe\_vendor$)+normalize($cpe\_product$)

\FORALL{$wad\_name \in wad\_names$}

\IF{normalize($wad\_name$)$ = cpe\_name$}
		\STATE $matches+=wad\_name$
		\ELSIF{normalize($wad\_name$)=normalize($cpe\_product$)}
		\STATE $matches+=wad\_name$
		
		\ENDIF
\ENDFOR
\RETURN $matches$
%
%
%
%\STATE $wad\_normalized\_names\gets$ normalize($wad\_names$)
%\STATE $N\gets$ NumberOfTweets($D$)
% \FORALL{$wad\_name \in wad\_names$}
%  \STATE $N_c \gets$ Number of tweets in Class $c$
%  \STATE \begin{equation}prior(c) = \frac{N_c}{N}\end{equation}
%  \STATE $Tweets_c \gets $All Tweets in class $c$
%  \FORALL{$t \in V$}
%    \STATE $T_ct$ = No. of times term $t$ appeared in $Tweets_c$
%  \ENDFOR
%  \FORALL{$t \in V$}
%   \STATE \begin{equation}prob[t][c] = \frac{T_ct}{\sum^{t'}T_ct'+ 1}\end{equation}
%  \ENDFOR
%\ENDFOR

\end{algorithmic}
\caption{Name Matching Algorithm}
\label{matching_algo}
\end{algorithm}

\begin{algorithm}
\begin{algorithmic}
\STATE $matches\gets$ array()

\FORALL{$wad\_name \in wad\_names$}

\IF{normalize($wad\_name$)$ = $normalize($cpe\_vendor$)}
		\STATE $matches+=wad\_name$
		\ELSE
		\STATE $cpe\_name\gets cpe\_vendor + cpe\_product$ 
		\STATE $found\gets$ True
		\FORALL {$wad\_word \in wad\_name$}
		\IF { $wad\_word$ is not a word in $cpe\_name$}
		\STATE $found\gets$ False
		\ENDIF
		\ENDFOR
		\IF {$found=True$}
		\STATE $matches+=wad\_name$
		\ENDIF
		\ENDIF
\ENDFOR
\end{algorithmic}
\caption{Name Matching Algorithm}
\label{matching_algo_2}
\end{algorithm}


%\end{framed}
%\begin{algorithm}
%\caption{My algorithm}\label{euclid}
%\begin{algorithmic}[1]
%\Procedure{MyProcedure}{}
%\State $\textit{stringlen} \gets \text{length of }\textit{string}$
%\State $i \gets \textit{patlen}$
%\BState \emph{top}:
%\If {$i > \textit{stringlen}$} \Return false
%\EndIf
%\State $j \gets \textit{patlen}$
%\BState \emph{loop}:
%\If {$\textit{string}(i) = \textit{path}(j)$}
%\State $j \gets j-1$.
%\State $i \gets i-1$.
%\State \textbf{goto} \emph{loop}.
%\State \textbf{close};
%\EndIf
%\State $i \gets i+\max(\textit{delta}_1(\textit{string}(i)),\textit{delta}_2(j))$.
%\State \textbf{goto} \emph{top}.
%\EndProcedure
%\end{algorithmic}
%\end{algorithm}

%write an algorithm in latex 
 
\subsection{Evaluation}

\subsubsection{False Positives}
Very generic WAD names result into false positives. Table \ref{table:false_positives} shows some examples of the incorrect matches due to the generic WAD names. 
\begin{table}
\begin{center}
    \begin{tabular}{ | c | c | }
    
    \hline
	  \hhline{|*2-}
	%\rowcolor{LightBlue} 
    \multicolumn{1}{|c|}{\cellcolor{LightBlue}\textbf{CPE}} & \multicolumn{1}{|c|}{\cellcolor{LightBlue}\textbf{WAD Name}}  
    \\ \hline
    % cpe:/o:microsoft:windows_xp:::home
    % cpe:/h:samsung:galaxy_note_2:-"
    % cpe:/a:wordpress:wordpress:1.0
    \texttt{cpe:/a:20\_20\_applications:20\_20\_auto\_gallery} & Gallery
        \\ \hline
    \texttt{cpe:/a:altiris:dell\_client\_manager\_solution} & Dell
        \\ \hline
    \texttt{cpe:/a:redhat:cygwin} & Red Hat
        \\ \hline
    \end{tabular}
    \caption{False Matches}
    \label{table:false_positives}
   \end{center}
%      \footnotesize{(*) \url{http://galleryproject.org/}\\
%      (**) Dell Printer Software \\
%      (***) Red Hat Operating System. It would be possible to prevent this false positive case by checking the catagory of the WAD name. The WAD category is \texttt{operating system}, while the CPE type is \texttt{application}, therefore, the matching should be refused. 
%      }
\end{table}

\subsubsection{False Negatives}
Finding false negatives, or in other words, the matches that were not found, is more difficult that false positives; because it involves going through both lists of WAD names and CPE names and finding matches manually to compare them with the algorithm output. Our algorithm might miss some mappings because of slight differences in product names for example  \texttt{cpe:/a:yandex.metrics\_project:yandex\_metrics:1.0} won't be matched to \textit{Yandex.Metrika} or \texttt{cpe:/a:microsoft:outlook\_web\_access} won't match to \textit{Outlook Web App}. A possible improvement would be to use string distance algorithms to find similar names; however, that will make the algorithm much more complex.
//
Another cause of false negatives is inconsistency in word boundaries. Imagine a CPE name in the format of \texttt{cpe:/a:adobe:adobe\_coldfusion}, it won't match to \textit{Cold Fusion}, because \ref{matching_algo_2} of the algorithm looks for the WAD name in CPE product name conserving the word boundaries. In this case the algorithm needs to check if WAD names are a substring of CPE names, but that will lead into many more false positives.

\section{Vulnerable Resources}
\paragraph{}
Now that we know which WAD names are affected by a vulnerability, obtaining the list of vulnerable resources is quite an easy task, because the data is already available in WAD output. The Vulnerability Notification Tool only needs to load the output of WAD, group resources by the technologies they use and for each vulnerability report the resources that use the affected WAD name.
\section{Output and Notifications}
\paragraph{}

Now the question is what are we going to do with all this vulnerability data? VNT stores the results of its findings in JSON format. Figure \ref{figure:json_output} illustrates a sample of the stored JSON file. These files contain vulnerability information, updates and affected WAD names. They are easy to parse and can be used later for more analysis about vulnerabilities.
In addition, the tool will send email notifications to the security team members whenever there is a vulnerability that affects CERN and has a higher CVSS score than 6.0. Figure \ref{figure:email_output} shows one of the emails sent by the tool.
%todo: email photo
\\
\begin{figure}[h!]
\label{figure:json_output}
  \centering
    \includegraphics[width=1.0\textwidth]{json}
  \caption{Sample JSON output}
\end{figure}

\begin{figure}[h!]
\label{figure:email_output}
  \centering
    \includegraphics[width=1.0\textwidth]{email}
  \caption{Sample Notification Email}
\end{figure}


\section{Results}

\paragraph{}
As mentioned before, there is no archive of NVD modified feeds available online; however, we had downloaded and stored NVD modified feeds since 31.10.2014 and we could use this data to simulate the tool over the period of time from 01.11.2014 to 31.12.2014 (2 months). Table \ref{table:vnt_results} shows the results of this simulation. The feed from 31.10.2014 has been used for the first execution of the tool and initializing the local copy of vulnerabilities. Appendix \ref{vnt_evaluation_method} describs the methods used to get these numbers from VNT output.

\begin{table}
\begin{center}
    \begin{tabular}{ | c || c | c || c | c |}
    
    \hline
	 
     &  \multicolumn{2}{c||}{New Vulnerabilities} &  \multicolumn{2}{c|}{Changes in Vulnerabilities}  
	\\ \hline   
      &  All &  At CERN &  All &  At CERN
    \\ 
	\hline    
  %  \hhline{|*5-}
       All & \multicolumn{1}{|c|}{\cellcolor{red!25}1098}   &  31 & \multicolumn{1}{|c|}{\cellcolor{red!25}2131}  & 238 
    %\\ \hhline{|*5-}
   \\ \hhline{|*5-}
\hhline{~~|-|~|-|}
Critical\textsuperscript{*} & 190  & \multicolumn{1}{|c||}{\cellcolor{green!25}9}  & 622  & \multicolumn{1}{|c|}{\cellcolor{green!25}95  }
    \\ \hline
    \end{tabular}
    \caption{VNT Results from 01.11.2014 to 31.12.2014}
    \label{table:vnt_results}
   \end{center}
   \footnotesize{(*) Vulnerabilities with a CVSS score equal to or greater than 6.0 are considered critical}
    \end{table}


\paragraph{}
Knowing about all the published vulnerabilities regardless of the fact that they affect CERN could be important for the security team and that is why the JSON output of the tool stores all the vulnerabilities it finds regardless of their their severity level or impact on CERN. On the other hand, if we send an email for every new vulnerability or a change in vulnerabilities we will be flooding the users' mailbox with an average of (1098+2131)/60 = 54 emails per day. Based on the findings illustrated in table \ref{table:vnt_results}, we decided to send emails for vulnerabilities that affect CERN and have a CVSS score equal to or greater than 6.0. In other words, the security team will receive an email whenever a new critical vulnerability is published or there is a change in a critical vulnerability that affects CERN. Using this strategy, we would be expecting an average of (9+95)/60= 2 emails per day. 
\begin{figure}[h!]
\label{figure:emails_per_wad}
  \centering
    \includegraphics[width=1.0\textwidth]{emails_per_wad}
  \caption{Number of Emails per WAD Name}
\end{figure}

\paragraph{}
Now we are going to have a closer look at the critical vulnerabilities that affected CERN (The green cells from table \ref{table:vnt_results}) to evaluate the tool and we will present some statistical data obtained from the tool.
Figure \ref{figure:emails_per_wad} shows the number of emails that would be sent per each WAD name. This chart contains only the WAD names that occur more than once. From this figure one can get an idea of what are the most vulnerable technologies that are being used at CERN. But we should keep in mind that the accuracy of our name matching algorithm has a direct impact on the number of emails we send for each WAD name. For example, if we look at all the vulnerabilities that have been matched to the WAD name `Red Hat', we realize that among the 21 emails that are sent, only 12 of them are in fact referring to the Red Hat operating system and the  other 9 are a consequence of false positives in our matching algorithm. Figure \ref{figure:emails_per_wad_fp} shows the number of true positive and false positive emails per WAD name and can be a better indicator of most vulnerable products at CERN. For example, although more emails were sent about Debian, it does not mean that Debian has been more vulnerable than OpenSSL.
\\
\begin{figure}[h!]
\label{figure:emails_per_wad_fp}
  \centering
    \includegraphics[width=1.0\textwidth]{emails_per_wad_fp}
  \caption{Number of Emails per WAD Name}
\end{figure}


\begin{figure}[h!]
\label{figure:fp_rate}
  \centering
    \includegraphics[width=1.0\textwidth]{fp_rate}
  \caption{False Positive Rate in Name Matching}
\end{figure}


Figure \ref{figure:fp_rate} shows that in 23\% of the cases the matching from the CPE to a WAD name has been wrong (too generic WAD names like `Red Hat'). The accuracy of the matches has been checked manually to get the data for this chart.
\\
Table \ref{table:vnt_results} shows that in 90\%  of the cases the email contains updated vulnerability information. Looking at the updated fields we can see that most of the times the affected products (CPEs) change. Figure \ref{figure:updates} shows the frequency of changes in different fields. Further investigation shows that CVSS Score has always changed from "None" to a value. This is expected as usually it takes some time (one or two days) until the CVSS score is available and once it is available it is highly reliable as it does not change. This holds also for CPE changes and we can see that in only 20\% of the cases the CPE field changes from a non empty value.




\begin{figure}[h!]
\label{figure:updates}
  \centering
    \includegraphics[width=1.0\textwidth]{updates}
  \caption{Updated Fields in Vulnerabilities}
\end{figure}

\section{Conclusion}
\begin{framed}
\textbf{The Vulnerability Notification Tool} is a tool that downloads the latest ``modified" feed from NVD, finds the vulnerabilities that are newly published or have been changed since its last execution and for each of these vulnerabilities reports CVE-ID, description, CVSS score, published date and time, last modified date and time, and a list of affected software (vulnerable software in CPE format). In addition, the tool lists the URL of the CERN websites and web servers that are likely to have this vulnerability.
\end{framed} 















